{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe004a032aa4759333b54e3b59943d6c06235f4e"
   },
   "source": [
    "Tutorial em texto para os inscritos no meu curso de Machine Learning na Udemy sobre a classificação de textos utilizando a biblioteca Scikit-learn.\n",
    "\n",
    "O objetivo é treinar um algoritmo para classificar corretamente o tema de notícias com base no texto escrito.\n",
    "\n",
    "Iremos utilizar um conjunto de dados com milhares de notícias em inglês e treinar o algoritmo para indentificar se a notícia é sobre \"Ateímos\", \"Cristianismo\", \"Computação Gráfica\" ou \"Ciências Médicas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "191e84babd0de77fbfc309cd575176b07630d59e"
   },
   "source": [
    "**Pré-processamento dos dados (Pre-processing)**\n",
    "\n",
    "Quando trabalhamos com textos, precisamos realizar algumas técnicas de pré-processamento dos dados para extrair algumas *features* importantes.\n",
    "\n",
    "O primeiro passo é construir um dicionário usando *CountVectorizer* que cria uma contagem de ocorrência de cada palavra nos textos. Quando maior o índice, mais ocorrência ocorre desta palavra, veja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "9adcf24bba581253d81867732cce2dbb23bddd9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muita frequência do termo 'of' -> 23610\n",
      "Frequência menor do termo 'algorithm' -> 4690\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "print(\"Muita frequência do termo 'of' -> \"+str(count_vect.vocabulary_.get(u'of')))\n",
    "print(\"Frequência menor do termo 'algorithm' -> \"+str(count_vect.vocabulary_.get(u'algorithm')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c8a22a72e3cda7c99c6dcf5fa5e25389d53fec0"
   },
   "source": [
    "Para evitar que textos longos, onde ocorrem mais frequências de palavras, tenham um resultado diferente de textos curtos, por mais que ambos falem sobre o mesmo tema, é necessário criar uma outra *feature* para capturar isso. Chamamos essa *feature* de **Term Frequencies** ou simplesmente **tf**, onde dividimos o número de ocorrências de cada palavra pelo total de palavras no documento.\n",
    "\n",
    "Realizamos mais uma transformação chamada de **idf** ou **Inverse Document Frequency**, que diminui o peso de palavras que se repetem muitas vezes entre os diferentes textos (exemplo: of, the, are, you, etc..), por serem menos informativas e não ajudarem na análise.\n",
    "\n",
    "Ambas as transformações são realizadas em uma mesma função chamada *fit_transform*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "68a6fd06657e7c7602de76826497e08f25c82dff"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0e53b4a04971b28f73400a8991caaaee0a33dda"
   },
   "source": [
    "**Treinando o modelo**\n",
    "\n",
    "Em alguns materiais de machine learning é comum encontrar o nome *classifier* como sinonimo de *model*, ou seja, como nome para referenciar o algoritmo de machine learning utilizado.\n",
    "\n",
    "Neste caso, utilizaremos o classifier *Multinomial Naive Bayes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "011b73a0f37104e905d8d6eb6cd3f313c0a95b56",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "115644a058c2c4f577b267418030a32e91d298e9"
   },
   "source": [
    "Vamos utilizar o algoritmo para tentar classificar duas frases \"God is love\" e \"OpenGL on the GPU is fast\". Sendo a primeira relacionada a categoria \"Cristianismo\" e a segunda a catergoria \"Computação Gráfica\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "36599eefe87f9c88ce5b4511cfa33f347b1cb7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b84363edf9371ecc55761dc6861950d53661b5fa"
   },
   "source": [
    "Conseguimos ver que o algoritmo identificou corretamente a categoria das duas frases!\n",
    "\n",
    "Podemos utilizar neste exemplo uma técnica muito utilizada em Machine Learning chamada Pipeline. Que é simplesmente colocar as diversas transformações dos dados e o próprio algoritmo em uma mesma função, sem precisar realizar o pre-processing e a escolha do algoritmo em separado. Basicamente funciona como uma **sequência** de tarefas que serão realiza com os dados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a470de81fd45ff00278a19272d25d79da359910a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78d2c80e4986b93ae2268453f42c02720bfa8902"
   },
   "source": [
    "Podemos calcular facilmente a precisão do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ceedaa27e19068d97469f28462dbf7203d9df4b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "379126ff4f2c7a911dbc32476e1ecad7089af5fc"
   },
   "source": [
    "Nosso modelo conseguiu prever com **83%** de precisão o tema dos textos dos dados de teste corretamente!\n",
    "\n",
    "Podemos alterar o *classifier* para ver se o resultado melhora. Vamos testar com um algoritmo de *support vector machine* (SVM), mais precisamente o *SGDClassifier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "688cb07822e35c047f16538f8d201f8ed3fc01ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c1e608d92222235795349eae4ea5da94b6dcbd0"
   },
   "source": [
    "A precisão aumentou bastante! Para **91,27%**!\n",
    "\n",
    "Neste exemplo prático podemos utilizar também a técnica de *GridSearch*, para encontrar os melhores Hyperparâmetros para este modelo.\n",
    "\n",
    "Bascimente vamos rodar o modelo diversas vezes trocando os parâmetros do pipeline e descobrir os melhores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "18750c43ff23518b322dadf7760d15aa4e0b5f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151349867929058\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__alpha': (1e-2, 1e-3),}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d4f333e5b625a35b9c30fe1704e0a1ff0aff3a3"
   },
   "source": [
    "Conseguimos melhorar ainda mais o modelo! Utilizando os hyperparâmetros alpha: 0.001 com transformação de idf e vetorização com escala (1, 2), o modelo subiu sua precisão para **91,51%**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
